{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification with a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will learn to:**\n",
    "- Build the general architecture of a neural network using TensorFlow, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent) to update the parameters\n",
    "- Make predictions and check the accuracy of your classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs & GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Overview of the MNIST data set ##\n",
    "\n",
    "We'll be using a dataset known as MNIST containing:\n",
    "    - a training set of 55000 images of handwritten digits labeled with the correspoding number\n",
    "    - a test set of 10000 images labeled with the correct number\n",
    "    - each image is of shape (28, 28). Thus, each image is square (height = 28) and (width = 28).\n",
    "\n",
    "You will build a simple image-recognition algorithm that can correctly classify the images among 10 categories i.e. 0,1,2,3,4,5,6,7,8,9.\n",
    "\n",
    "Let's get more familiar with the dataset. Load the data by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape, mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line of `mnist.train.images` and `mnist.test.images` is an array representing an image. \n",
    "\n",
    "The images have been flattened i.e. converted from 28 x 28 array to 784.\n",
    "\n",
    "Each line of `mnist.train.labels.shape` and `mnist.test.labels.shape` is a array size 10, because the class labels are in [one-hot encoded](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) form.\n",
    "\n",
    "You can visualize an example by running the following code. Feel free also to change the `index` value and re-run to see other images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of an image\n",
    "index = 0\n",
    "first_image = mnist.train.images[index]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "first_image = first_image.reshape((28,28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Neural Network model using TensorFlow\n",
    "\n",
    "We are going to train a Neural Network with two hidden layers.\n",
    "\n",
    "The general methodology to build a Neural Network is to:\n",
    "    1. Define the neural network structure ( no. of input units,  no. of hidden units, etc). \n",
    "    2. Initialize the model's parameters\n",
    "    3. Loop:\n",
    "        - Implement forward propagation\n",
    "        - Compute loss\n",
    "        - Implement backward propagation to get the gradients\n",
    "        - Update parameters (gradient descent)\n",
    "\n",
    "### 3.1 - Defining the neural network structure ####\n",
    "\n",
    "Define three variables:\n",
    "    - n_input: the size of the input layer\n",
    "    - n_h1: the size of the first hidden layer (randomly taken to be 400, try different values)\n",
    "    - n_h2: the size of the first hidden layer (randomly taken to be 200)\n",
    "    - n_classes: the size of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_h1 = 400\n",
    "n_h2 = 200\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Initialize the model's parameters ####\n",
    "\n",
    "- We will initialize the weights matrices with random values in the form of a dictionary. \n",
    "    - We use: `tf.random_normal([a,b])` to initialize a matrix of shape (a,b) with random values from a normal distribution.\n",
    "- We will initialize these weight matrices as TensorFlow variable to add it to the computation graph. \n",
    "    - We use: `tf.Variable(M)` to initialize a matrix M as a TensorFlow tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_h1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_h1, n_h2])),\n",
    "    'output': tf.Variable(tf.random_normal([n_h2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_h1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_h2])),\n",
    "    'output': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Forward Propagation module ####\n",
    "\n",
    "We implement a `forward_propagation()` function to do the matrix multiplications and predict outputs labels for the images.\n",
    "\n",
    "- The steps we implement are:\n",
    "    1. Retrieve each weight and bias from the dictionaries \"wts\" and \"biases\"  by using `wts[\"..\"]` and `biases[\"..\"]`.\n",
    "    2. Implement Forward Propagation. Compute the vector of all your predictions on all the examples in the training set.\n",
    "- We make use of TensorFlow math functions like `tf.matmul()` and `tf.add()` to calculate $Z{} =  W^{} X^{} + b^{}$ and then pass $Z$ through a [`ReLU`](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) activation function.\n",
    "    - **ReLU**: The mathematical formula for ReLU is  $RELU(Z) = max(0, Z)$.  We make use of `tf.nn.relu()` function provided by TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, wts, biases):\n",
    "    layer1_in = tf.add(tf.matmul(X, wts['h1']), biases['h1'])\n",
    "    layer1_out = tf.nn.relu(layer1_in)\n",
    "    \n",
    "    layer2_in = tf.add(tf.matmul(layer1_out, wts['h2']), biases['h2'])\n",
    "    layer2_out = tf.nn.relu(layer2_in)\n",
    "    \n",
    "    output = tf.add(tf.matmul(layer2_out, wts['output']), biases['output'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder('float',[None, n_input])\n",
    "Y = tf.placeholder(tf.int32,[None, n_classes])\n",
    "pred = forward_propagation(X, wts, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `tf.placeholder()` to assign X and Y. A placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the actual value or data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Cost function\n",
    "\n",
    "Now, we will implement forward along with backward propagation. We need to compute the cost, because we want to check if our model is actually learning.\n",
    "\n",
    "We compute the cross-entropy cost, using a similar formula for multi-class classification with k classes: $$- \\sum\\limits_{i = 1}^{k} y_{true}\\log\\left(y_{pred}\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Backward propagation module\n",
    "\n",
    "### 5.1 - Optimizer####\n",
    "\n",
    "Now, we choose an optimizer like `AdamOptimizer` and use it to minimise our cost function according to a fixed learning rate and epochs (number of iterations) defined by us. We can play around with different values of `learning_rate` and `epochs` to reach the optimum values of parameters for our network.\n",
    "- Here we use `tf.train.AdamOptimizer()` to train our model. This optimizer provided by TensorFlow tries to minimize the `cost` using back-propagation to push back the gradients and update the parameters of our network.\n",
    "- This is done not once but `epochs` number of times over batches of the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize learning rate and no. of epochs\n",
    "learning_rate = 0.01\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Session ####\n",
    "\n",
    "Everything we have done until now has led to the creation of a static computational graph i.e. the values haven't been actually calculated, but the sequence of calculations that need to happen is well-defined and ready.\n",
    "\n",
    " - TensorFlow uses the `tf.Session` class to represent a connection between this Python program and the C++ runtime. A `tf.Session` object provides access to devices in your local machine, and remote devices using the distributed TensorFlow runtime. It also caches information about your `tf.Graph` that is automatically generated until now so that you can efficiently run the same computation multiple times.\n",
    " \n",
    " \n",
    " - Basically, TensorFlow doesn't perform any operations on the way i.e. dynamically. You define and initialize all the variables & operations in the computational graphs, and then performs these computations at once when the `tf.Session` object is called.\n",
    " \n",
    " \n",
    " - `tf.global_variables_initializer()` initializes all the variables defined upto this point in this session, to be used in upcoming  computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Training process ####\n",
    "\n",
    "- We send the input to our model in mini-batches or subsets of the whole dataset instead of single examples. This is done to introduce enough generalization during training as an average effect of a batch is taken into consideration during back-propagation and while updating the parameters.\n",
    "- We can tweak the `batch_size` to see it's effect on training.\n",
    "- `sess.run()` is used to evaluate the computation graph of our network from scratch; we provide two variables to be evaluated during the `sess.run()` namely `cost` and `optimize` which minimizes the cost using `optimizer` defined earlier.\n",
    "- The argument `feed_dict` is used to feed values to TensorFlow placeholders `X` and `Y` that we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 27151.221010684967\n",
      "Cost after iteration 1: 4562.438317202032\n",
      "Cost after iteration 2: 2287.1990031975292\n",
      "Cost after iteration 3: 1527.6662657364832\n",
      "Cost after iteration 4: 1108.081490490848\n",
      "Cost after iteration 5: 1062.183263152381\n",
      "Cost after iteration 6: 881.5504170255284\n",
      "Cost after iteration 7: 831.2259050734397\n",
      "Cost after iteration 8: 682.6181012714269\n",
      "Cost after iteration 9: 678.6381763730144\n",
      "Cost after iteration 10: 445.37055889136275\n",
      "Cost after iteration 11: 446.78247913228097\n",
      "Cost after iteration 12: 397.0535288006125\n",
      "Cost after iteration 13: 325.1885979445384\n",
      "Cost after iteration 14: 285.3531211745165\n",
      "Cost after iteration 15: 256.26912213090145\n",
      "Cost after iteration 16: 209.50660549166574\n",
      "Cost after iteration 17: 152.00371034349763\n",
      "Cost after iteration 18: 145.08221521088535\n",
      "Cost after iteration 19: 153.00478714489736\n",
      "Cost after iteration 20: 136.2786254957373\n",
      "Cost after iteration 21: 106.05397274324787\n",
      "Cost after iteration 22: 110.16627493743351\n",
      "Cost after iteration 23: 123.00054991757497\n",
      "Cost after iteration 24: 92.72559686354361\n",
      "Cost after iteration 25: 89.69963174958775\n",
      "Cost after iteration 26: 73.13729604970649\n",
      "Cost after iteration 27: 79.7942920041969\n",
      "Cost after iteration 28: 64.324280220133\n",
      "Cost after iteration 29: 66.8576502973483\n",
      "Cost after iteration 30: 67.56781465589074\n",
      "Cost after iteration 31: 64.53695222242823\n",
      "Cost after iteration 32: 70.66708927683067\n",
      "Cost after iteration 33: 69.88474587058226\n",
      "Cost after iteration 34: 51.38299891910356\n",
      "Cost after iteration 35: 69.89416047650002\n",
      "Cost after iteration 36: 58.09900584123852\n",
      "Cost after iteration 37: 47.341321920738665\n",
      "Cost after iteration 38: 41.12513483231422\n",
      "Cost after iteration 39: 52.83284409547878\n",
      "Cost after iteration 40: 44.84439510711627\n",
      "Cost after iteration 41: 53.4233701811354\n",
      "Cost after iteration 42: 46.94742724430034\n",
      "Cost after iteration 43: 44.896093162079865\n",
      "Cost after iteration 44: 53.57184142260064\n",
      "Cost after iteration 45: 46.177538396271984\n",
      "Cost after iteration 46: 42.650057086052584\n",
      "Cost after iteration 47: 50.528677208998374\n",
      "Cost after iteration 48: 44.776222090637255\n",
      "Cost after iteration 49: 41.35444625510365\n"
     ]
    }
   ],
   "source": [
    "# Define a batch size\n",
    "batch_size = 100\n",
    "costs = []\n",
    "\n",
    "# Train the model\n",
    "for i in range(epochs):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={X:batch_x, Y:batch_y})\n",
    "        total_cost += c\n",
    "    \n",
    "    # Print the cost every iteration\n",
    "    print(\"Cost after iteration {}: {}\".format(i, total_cost))\n",
    "    costs.append(total_cost)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(costs)\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the graph that the cost reduces as it should. Try using different optimizers and cost functions to get an idea of what works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Making Predictions\n",
    "\n",
    "### 6.1 - Making predictions using our model####\n",
    "\n",
    "- We use `tf.argmax()` to return the index with the largest value across axes of a tensor. This is done to convert the one-hot encoded predictions to simple class labels.\n",
    "- We use `tf.equal()` to calculate the examples for which the predicted class label was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "true_labels = tf.argmax(Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_eval, labels, correct_pred = sess.run([predictions, true_labels, correct_predictions], feed_dict={X:mnist.test.images, Y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we input test examples & labels i.e. `mnist.test.images` & `mnist.test.labels`to our model via the `feed_dict` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Evaluating the accuracy####\n",
    "\n",
    "We evaluate the accuracy of our model using the `correct_pred` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([ True,  True,  True, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval, labels, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 9587/10000\n"
     ]
    }
   ],
   "source": [
    "# Calculating the number of predictions out of 10000 that our model labeled correctly\n",
    "print(\"Correct predictions: \"+str(correct_pred.sum())+\"/10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage Accuracy:  95.87\n"
     ]
    }
   ],
   "source": [
    "#Calculating percentage accuracy\n",
    "print(\" Percentage Accuracy: \", (correct_pred.sum()/correct_pred.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So as you can see, we achieved a pretty good accuracy for such a simple model; we can improve upon this further by tweaking the network structure, training process etc.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
